{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Face Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Completion of Images using GAN trained on Kaggle dataset - celeba "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras import layers, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_celeba_dataset(data_dir, validation_split, batch_size):\n",
    "    \n",
    "    data_dir = data_dir\n",
    "    image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255, validation_split= validation_split)   \n",
    "    train_generator = image_generator.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        subset='training')\n",
    "    \n",
    "    return train_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(3,(5,5), strides = (2,2) , padding = \"same\"  ,input_shape = (224,224,3)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(16,(5,5), strides = (2,2) , padding = \"same\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(32,(5,5), strides = (2,2) , padding = \"same\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(64,(5,5), strides = (2,2) , padding = \"same\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(128,(5,5), strides = (2,2) , padding = \"same\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(7*7*128 , use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    \n",
    "    model.add(tf.keras.layers.Reshape((7,7,128)))\n",
    "\n",
    "    model.add(tf.keras.layers.UpSampling2D())  #14X14\n",
    "    model.add(tf.keras.layers.Conv2D(128 , (5,5) , strides = (1,1), padding = \"same\")) #28x28\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.UpSampling2D())  #28X28\n",
    "    model.add(tf.keras.layers.Conv2D(64 , (5,5) , strides = (1,1), padding = \"same\")) #28x28\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.UpSampling2D())  #56X56\n",
    "    model.add(tf.keras.layers.Conv2D(32 , (5,5) , strides = (1,1), padding = \"same\")) #56x56\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "        \n",
    "    model.add(tf.keras.layers.UpSampling2D())  #112X112\n",
    "    model.add(tf.keras.layers.Conv2D(16 , (5,5) , strides = (1,1), padding = \"same\")) #112x112\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "        \n",
    "    model.add(tf.keras.layers.UpSampling2D())  #224X224\n",
    "    model.add(tf.keras.layers.Conv2D(3 , (5,5) , strides = (1,1), padding = \"same\" , activation = \"tanh\")) #28x28\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 112, 112, 3)\n",
      "(None, 56, 56, 16)\n",
      "(None, 28, 28, 32)\n",
      "(None, 14, 14, 64)\n",
      "(None, 7, 7, 128)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 112, 112, 3)       228       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 112, 112, 3)       12        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 112, 112, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 56, 56, 16)        1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 56, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6272)              39337984  \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6272)              25088     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 56, 56, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 112, 112, 16)      12816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 112, 112, 16)      64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 224, 224, 3)       1203      \n",
      "=================================================================\n",
      "Total params: 40,315,315\n",
      "Trainable params: 40,301,805\n",
      "Non-trainable params: 13,510\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = generator_model()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32,(5,5), strides = (2,2) , padding = \"same\"  ,input_shape = (224,224,3)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(64,(5,5), strides = (2,2) , padding = \"same\"  ,))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    \n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(128,(5,5), strides = (2,2) , padding = \"same\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(256,(5,5), strides = (2,2) , padding = \"same\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(1028,activation = \"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 112, 112, 32)      2432      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 56, 56, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 28, 28, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 256)       819456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1028)              51581956  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1029      \n",
      "=================================================================\n",
      "Total params: 52,662,985\n",
      "Trainable params: 52,662,025\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    \n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(real_output, fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    #return tf.norm(real_output - fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizers_and_checkpoint(gen_opt = tf.keras.optimizers.Adam(1e-4), disc_opt = tf.keras.optimizers.Adam(1e-4))\n",
    "    generator_optimizer = gen_opt\n",
    "    discriminator_optimizer = disc_opt\n",
    "    \n",
    "    checkpoint_dir = './training_checkpoints'\n",
    "    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "    checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                     discriminator_optimizer=discriminator_optimizer,\n",
    "                                     generator=generator,\n",
    "                                     discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the functions used for training the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    if DEBUG :\n",
    "        tf.print(\"Inside train_step\")\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(images, training=True)\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "      assert generated_images.shape == images.shape, \"Shape of images and generated images do not match\"\n",
    "\n",
    "      gen_loss = generator_loss(real_output, fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "            \n",
    "      tf.print(\"gen_loss : \", gen_loss, \"    \", \"disc_loss : \", disc_loss)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    if DEBUG :\n",
    "        tf.print(\"Gradients calculated and applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs, display_batch_number = False, DEBUG = False):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for j in range(len(dataset)):\n",
    "      if display_batch_number :\n",
    "          print(\"Going through batch number : \" + str(j+1))\n",
    "      train_step(dataset[j][0])\n",
    "\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time taken for this epoch {} is {} sec'.format(epoch + 1, time.time()-start))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  print(predictions[0].shape)    \n",
    "\n",
    "  fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "  for i in range(predictions[:16].shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[0])\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the already trained generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gen_disc(gen_dir, disc_dir, gen_opt = None, disc_output = None):\n",
    "\n",
    "    generator = tf.keras.models.load_model(gen_dir)\n",
    "    discriminator = tf.keras.models.load_model(disc_dir)\n",
    "    model_loaded = True\n",
    "    \n",
    "    if gen_opt and disc_output :\n",
    "        optimizers_and_checkpoint(gen_opt = gen_opt, disc_opt = disc_output)\n",
    "    else:\n",
    "        optimizers_and_checkpoint()\n",
    "    \n",
    "    return model_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(training_data, model_loaded, epochs, DEBUG = False):\n",
    "    \n",
    "    if model_loaded == True:\n",
    "        train(training_data, train_generator, epochs)\n",
    "    \n",
    "    if(model_loaded == False):\n",
    "        generator = generator_model()\n",
    "        discriminator = make_discriminator_model()\n",
    "        \n",
    "        if DEBUG :\n",
    "            generator.summary()\n",
    "            discriminator.summary()\n",
    "        \n",
    "        train(training_data, train_generator, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(seed, seed_number):    \n",
    "    \n",
    "    aa = tf.squeeze(seed[seed_number]).numpy()\n",
    "    print(aa.shape)\n",
    "\n",
    "    h = [75, 100]\n",
    "    v = [100, 125]\n",
    "    for i in range(v[0], v[1]):\n",
    "      for j in range(h[0], h[1]):\n",
    "        aa[i][j] = -1\n",
    "\n",
    "    c = tf.convert_to_tensor(aa)\n",
    "    c = tf.reshape(c, [1, 224, 224, 3])\n",
    "    c.shape\n",
    "\n",
    "    o = generator(c, training = False)\n",
    "\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2,figsize=(7, 8))\n",
    "    \n",
    "    ax1.set_title(\"Incomplete face\")\n",
    "    ax1.imshow(aa)\n",
    "    ax2.set_title(\"Generated Face by our Model\")\n",
    "    ax2.imshow(tf.squeeze(o))\n",
    "    ax3.set_title(\"Complete Face\")\n",
    "    ax3.imshow(tf.squeeze(seed[seed_number]).numpy())\n",
    "    ax4.set_title(\"Face Generated when \\n the complete image is input\")\n",
    "    ax4.imshow(tf.squeeze(generator(seed[seed_number].reshape(1,224,224,3))))\n",
    "    fig.savefig('/Users/tsanjevvishnu/Downloads/ica/gime8/epoch'+str(8)+'-image_number'+str(seed_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(seed_number)\n",
    "    for image_batch in training_generator :\n",
    "        seed = image_batch\n",
    "    \n",
    "    seed_number = seed_number\n",
    "    assert seed_number < 10, \"seed_number greater than size of the seed\"\n",
    "    \n",
    "    compare_results(seed = seed, \n",
    "                    seed_number = seed_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../generator_7/assets\n",
      "INFO:tensorflow:Assets written to: ../discriminator_7/assets\n"
     ]
    }
   ],
   "source": [
    "def model_save(generator_name, discriminator_name):\n",
    "    generator.save(generator_name)\n",
    "    discriminator.save(discriminator_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "The sixth model obtained gives good results and there is observed to be a good resemblance to human faces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = create_celeba_dataset('Users/tsanjevvishnu/Downloads/ica', 0.95, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = load_gen_disc('/Users/tsanjevvishnu/Downloads/ica/model/generator_6',\n",
    "                             '/Users/tsanjevvishnu/Downloads/ica/model/discriminator_6',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(training_data = training_generator, \n",
    "            model_loaded = model_loaded, \n",
    "            epochs = 1, \n",
    "            DEBUG = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save('/Users/tsanjevvishnu/Downloads/ica/model/generator_sanjev',\n",
    "           '/Users/tsanjevvishnu/Downloads/ica/model/discriminator_sanjev')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
